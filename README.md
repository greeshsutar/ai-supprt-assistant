# AI-Support-Assiistent- 
A lightweight RAG-based (Retrieval Augmented Generation) Support Assistant built using **Groq LLM + ChromaDB + LangChain + Streamlit**.

The agent answers user queries using your FAQ data, ensuring accurate and context-based responses.

---

## ğŸ“Œ 1. Overview  

This AI Support Assistant helps users get automated answers to common support questions.  
It uses:

- A **vector database (ChromaDB)** to store & retrieve FAQ data  
- **SentenceTransformer embeddings** to match similar questions  
- **Groq LLM (llama-3.3-70b-versatile)** for fast, accurate responses  
- **Streamlit** for the UI  

This makes the tool behave like a mini customer support agent.

---

## ğŸš€ 2. Features  

### âœ” **Context-aware answers**  
Uses RAG to answer strictly from provided FAQ data.

### âœ” **Fast inference with Groq**  
Groqâ€™s hosted LLM provides extremely high speed and low latency.

### âœ” **Expandable FAQ database**  
Simply update the `faqs.txt` file to add new knowledge.

### âœ” **Clean UI using Streamlit**  
Easy for users to interact and test the assistant.

---

## âš ï¸ 3. Limitations  

- Cannot answer questions **outside FAQ context**.  
- No authentication (anyone can access if deployed publicly).  
- Basic UI (no chat history).  
- Not suitable for *very large* knowledgebases without optimization.  

---

## ğŸ§  4. Architecture Diagram  

                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚        User (UI)         â”‚
                     â”‚  Streamlit Frontend      â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚  User Query
                                   â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚      SupportAgent         â”‚
                     â”‚ (Controls full pipeline)  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                  â”‚                  â”‚
                â”‚                  â”‚                  â”‚
                â–¼                  â”‚                  â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  ChromaDB Vector  â”‚         â”‚        â”‚ SentenceTransformer â”‚
      â”‚     Database      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  Embedding Model     â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   Similarity      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â–²   â”‚              Search                â–²
            â”‚   â”‚                                    â”‚
            â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                   â”‚
            â”‚       Relevant FAQ Snippets
            â”‚                   â”‚
            â–¼                   â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚       Groq LLM (llama-3.3-70b-versatile)     â”‚
       â”‚  Generates the final answer using context     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚     Final Answer         â”‚
                      â”‚  Shown in Streamlit UI   â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ› ï¸ 5. Tech Stack & Models Used
ğŸ”¹ Backend & AI

Groq LLM: llama-3.3-70b-versatile

SentenceTransformer: all-MiniLM-L6-v2 for embeddings

LangChain for text splitting & retrieval pipeline

ChromaDB for vector storage

Python 3.10

ğŸ”¹ Frontend

Streamlit (interactive user interface)

ğŸ”¹ Other Tools

dotenv for API key management

pandas for handling text data

GitHub for version control

Streamlit Cloud for deployment

âš™ï¸ 6. Setup & Installation Instructions
# 1. Clone repository
git clone https://github.com/<your-username>/AI-Support-Assiistent-.git
cd AI-Support-Assiistent-

# 2. Create virtual environment
python -m venv venv
venv\Scripts\activate   # on Windows
# OR
source venv/bin/activate  # Mac/Linux

# 3. Install required packages
pip install -r requirements.txt

# 4. Create .env file
touch .env

# Add inside .env:
GROQ_API_KEY=your_api_key_here

# 5. Run the app
streamlit run app.py

7. Project Structure (Required)
AI-Support-Assiistent-/
â”‚
â”œâ”€â”€ app.py                     # Streamlit UI
â”œâ”€â”€ agent.py                   # Main support agent logic
â”œâ”€â”€ retriever.py               # RAG system (Chroma + Embeddings)
â”œâ”€â”€ list_models.py             # Utility to list Groq models
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ faqs.txt               # FAQ knowledge base
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env.example               # Example env file
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

8. Potential Improvements
Future Enhancements

Add chat history for multi-turn conversations

Add authentication for restricted access

Add admin panel to upload FAQs dynamically

Use bigger embedding models for better retrieval

Add feedback system (thumbs up/down)

Improve UI design with animations + branding

Deploy using Docker or HuggingFace Spaces


9. Demo Link
ğŸ”— Live Demo:
https://<your-streamlit-cloud-url>


